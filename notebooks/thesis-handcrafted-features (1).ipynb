{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94842836",
   "metadata": {
    "papermill": {
     "duration": 0.003001,
     "end_time": "2025-12-19T19:09:15.571669",
     "exception": false,
     "start_time": "2025-12-19T19:09:15.568668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Full Handcrafted Features Pipeline (Lab* + GLCM + Stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423d1b09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:09:15.577466Z",
     "iopub.status.busy": "2025-12-19T19:09:15.576801Z",
     "iopub.status.idle": "2025-12-19T19:09:15.693839Z",
     "shell.execute_reply": "2025-12-19T19:09:15.693044Z"
    },
    "papermill": {
     "duration": 0.12153,
     "end_time": "2025-12-19T19:09:15.695333",
     "exception": false,
     "start_time": "2025-12-19T19:09:15.573803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/processed-images-224x224/Grade 1: 1084 images\n",
      "/kaggle/input/processed-images-224x224/Grade 2: 1050 images\n",
      "/kaggle/input/processed-images-224x224/Grade 3: 1503 images\n",
      "/kaggle/input/processed-images-224x224/Grade 4: 966 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"/kaggle/input/processed-images-224x224\"\n",
    "for grade in [\"Grade 1\", \"Grade 2\", \"Grade 3\", \"Grade 4\"]:\n",
    "    folder = os.path.join(data_dir, grade)\n",
    "    count = len([f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]) if os.path.exists(folder) else 0\n",
    "    print(f\"{folder}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359445f7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-19T19:09:15.701000Z",
     "iopub.status.busy": "2025-12-19T19:09:15.700728Z",
     "iopub.status.idle": "2025-12-19T19:09:22.063004Z",
     "shell.execute_reply": "2025-12-19T19:09:22.062394Z"
    },
    "papermill": {
     "duration": 6.367105,
     "end_time": "2025-12-19T19:09:22.064679",
     "exception": false,
     "start_time": "2025-12-19T19:09:15.697574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from skimage.feature import graycomatrix, graycoprops \n",
    "from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------ FEATURE EXTRACTION ------------------\n",
    "\n",
    "def load_and_convert_to_lab(image_path):\n",
    "    \"\"\"Load image and convert directly to L*a*b* (no background removal).\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "    return img_lab\n",
    "\n",
    "def extract_color_histograms(lab_img, bins=32):\n",
    "    \"\"\"Extract normalized histograms for a* and b* channels.\"\"\"\n",
    "    a_channel = lab_img[:, :, 1]\n",
    "    b_channel = lab_img[:, :, 2]\n",
    "    hist_a, _ = np.histogram(a_channel.ravel(), bins=bins, range=(0, 256), density=True)\n",
    "    hist_b, _ = np.histogram(b_channel.ravel(), bins=bins, density=True)\n",
    "    return np.concatenate([hist_a, hist_b])\n",
    "\n",
    "def extract_statistical_features(lab_img):\n",
    "    \"\"\"Mean, std, skew for L*, a*, b*.\"\"\"\n",
    "    features = []\n",
    "    for i in range(3):  # L=0, a=1, b=2\n",
    "        channel = lab_img[:, :, i].astype(np.float64)\n",
    "        mean = np.mean(channel)\n",
    "        std = np.std(channel)\n",
    "        skew = (np.mean((channel - mean) ** 3)) / (std ** 3 + 1e-6)\n",
    "        features.extend([mean, std, skew])\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_glcm_features(lab_img, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"GLCM on L* channel (luminance = texture).\"\"\"\n",
    "    l_channel = lab_img[:, :, 0]\n",
    "    l_ubyte = img_as_ubyte(l_channel / 255.0)  # Normalize to [0,1] then to 8-bit\n",
    "    \n",
    "    features = []\n",
    "    for dist in distances:\n",
    "        for angle in angles:\n",
    "            glcm = graycomatrix(l_ubyte, distances=[dist], angles=[angle], levels=256, symmetric=True, normed=True)\n",
    "            for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']:\n",
    "                features.append(graycoprops(glcm, prop)[0, 0])\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_features(image_path):\n",
    "    \"\"\"Main feature extractor ‚Äî no background removal.\"\"\"\n",
    "    try:\n",
    "        lab_img = load_and_convert_to_lab(image_path)\n",
    "        hist_feat = extract_color_histograms(lab_img)\n",
    "        stat_feat = extract_statistical_features(lab_img)\n",
    "        glcm_feat = extract_glcm_features(lab_img)\n",
    "        return np.concatenate([hist_feat, stat_feat, glcm_feat])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ------------------ DATA LOADING ------------------\n",
    "\n",
    "def load_dataset(data_dir=\"/kaggle/input/processed-images-224x224\"):\n",
    "    \"\"\"\n",
    "    Load images from your actual folder structure:\n",
    "    /kaggle/input/processed-images-224x224/Grade 1/\n",
    "    /kaggle/input/processed-images-224x224/Grade 2/\n",
    "    etc.\n",
    "    \"\"\"\n",
    "    grade_folders = {\n",
    "        'Grade 1': 0,\n",
    "        'Grade 2': 1,\n",
    "        'Grade 3': 2,\n",
    "        'Grade 4': 3\n",
    "    }\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for grade_name, label in grade_folders.items():\n",
    "        folder_path = os.path.join(data_dir, grade_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"‚ö†Ô∏è Warning: Folder not found: {folder_path}\")\n",
    "            continue\n",
    "        \n",
    "        for f in os.listdir(folder_path):\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                image_paths.append(os.path.join(folder_path, f))\n",
    "                labels.append(label)\n",
    "    \n",
    "    print(f\"üìÅ Loaded {len(image_paths)} images from {data_dir}\")\n",
    "    return image_paths, labels\n",
    "\n",
    "# ------------------ FEATURE EXTRACTION RUNNER ------------------\n",
    "\n",
    "def extract_dataset_features():\n",
    "    \"\"\"No resolution argument ‚Äî uses fixed input path.\"\"\"\n",
    "    print(\"üîÑ Extracting handcrafted features from /kaggle/input/processed-images-224x224/...\")\n",
    "    image_paths, labels = load_dataset()  # Uses default path\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        raise ValueError(\"‚ùå No images found! Check your input folder structure.\")\n",
    "    \n",
    "    features = []\n",
    "    valid_paths, valid_labels = [], []\n",
    "    \n",
    "    for path, label in tqdm(zip(image_paths, labels), total=len(image_paths)):\n",
    "        feat = extract_features(path)\n",
    "        if feat is not None:\n",
    "            features.append(feat)\n",
    "            valid_paths.append(path)\n",
    "            valid_labels.append(label)\n",
    "    \n",
    "    if len(features) == 0:\n",
    "        raise RuntimeError(\"‚ùå All feature extractions failed.\")\n",
    "    \n",
    "    X = np.array(features)\n",
    "    y = np.array(valid_labels)\n",
    "    print(f\"‚úÖ Extracted {X.shape[0]} samples with {X.shape[1]} features\")\n",
    "    return X, y, valid_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264627e",
   "metadata": {
    "papermill": {
     "duration": 0.002186,
     "end_time": "2025-12-19T19:09:22.069299",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.067113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Anti-Overfitting Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b5fca6",
   "metadata": {
    "papermill": {
     "duration": 0.002152,
     "end_time": "2025-12-19T19:09:22.073546",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.071394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### To find the best model without overfitting, use this 3-stage validation strategy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa58979",
   "metadata": {
    "papermill": {
     "duration": 0.002078,
     "end_time": "2025-12-19T19:09:22.077711",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.075633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Experiment 1: Model Selection with Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf79267",
   "metadata": {
    "papermill": {
     "duration": 0.00208,
     "end_time": "2025-12-19T19:09:22.081861",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.079781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Goal: Unbiased comparison of SVM vs Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69bc9f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:09:22.087411Z",
     "iopub.status.busy": "2025-12-19T19:09:22.087081Z",
     "iopub.status.idle": "2025-12-19T19:09:22.094294Z",
     "shell.execute_reply": "2025-12-19T19:09:22.093523Z"
    },
    "papermill": {
     "duration": 0.011681,
     "end_time": "2025-12-19T19:09:22.095721",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.084040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_selection_nested_cv(X, y, n_splits=5):\n",
    "    \"\"\"Nested CV: outer loop for evaluation, inner loop for hyperparameter tuning.\"\"\"\n",
    "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    models = {\n",
    "        'SVM': {\n",
    "            'model': SVC(random_state=42),\n",
    "            'params': {\n",
    "                'C': [0.1, 1, 10, 100],\n",
    "                'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
    "            }\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, cfg in models.items():\n",
    "        print(f\"\\nüîç Evaluating {name} with Nested CV...\")\n",
    "        outer_scores = []\n",
    "        \n",
    "        for train_idx, test_idx in outer_cv.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            # Standardize features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Inner CV for hyperparameter tuning\n",
    "            inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            grid = GridSearchCV(cfg['model'], cfg['params'], cv=inner_cv, scoring='f1_weighted', n_jobs=-1)\n",
    "            grid.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluate on outer test set\n",
    "            y_pred = grid.predict(X_test_scaled)\n",
    "            score = f1_score(y_test, y_pred, average='weighted')\n",
    "            outer_scores.append(score)\n",
    "        \n",
    "        results[name] = {\n",
    "            'mean_f1': np.mean(outer_scores),\n",
    "            'std_f1': np.std(outer_scores),\n",
    "            'scores': outer_scores\n",
    "        }\n",
    "        print(f\"  ‚Üí Mean F1: {np.mean(outer_scores):.4f} ¬± {np.std(outer_scores):.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bee54",
   "metadata": {
    "papermill": {
     "duration": 0.002121,
     "end_time": "2025-12-19T19:09:22.100036",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.097915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Experiment 2: Feature Ablation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b22274",
   "metadata": {
    "papermill": {
     "duration": 0.002143,
     "end_time": "2025-12-19T19:09:22.104414",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.102271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Goal: Understand which feature groups (color, stats, texture) matter most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6ac6fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:09:22.110005Z",
     "iopub.status.busy": "2025-12-19T19:09:22.109498Z",
     "iopub.status.idle": "2025-12-19T19:09:22.116357Z",
     "shell.execute_reply": "2025-12-19T19:09:22.115633Z"
    },
    "papermill": {
     "duration": 0.011107,
     "end_time": "2025-12-19T19:09:22.117770",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.106663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_ablation_study(X, y, feature_lengths):\n",
    "    \"\"\"Test performance with subsets of features.\"\"\"\n",
    "    hist_len = feature_lengths['hist']\n",
    "    stat_len = feature_lengths['stat']\n",
    "    glcm_len = feature_lengths['glcm']\n",
    "    \n",
    "    feature_sets = {\n",
    "        'Color Histograms': (0, hist_len),\n",
    "        'Statistical Features': (hist_len, hist_len + stat_len),\n",
    "        'Texture (GLCM)': (hist_len + stat_len, hist_len + stat_len + glcm_len),\n",
    "        'Color + Stats': (0, hist_len + stat_len),\n",
    "        'Color + Texture': (0, hist_len) + (hist_len + stat_len, hist_len + stat_len + glcm_len),  # tuple hack\n",
    "        'Stats + Texture': (hist_len, hist_len + stat_len + glcm_len),\n",
    "        'All Features': (0, X.shape[1])\n",
    "    }\n",
    "    \n",
    "    best_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "    results = {}\n",
    "    \n",
    "    for name, idx in feature_sets.items():\n",
    "        if isinstance(idx, tuple) and len(idx) == 4:  # Handle combined non-contiguous\n",
    "            X_subset = np.concatenate([X[:, idx[0]:idx[1]], X[:, idx[2]:idx[3]]], axis=1)\n",
    "        else:\n",
    "            X_subset = X[:, idx[0]:idx[1]]\n",
    "        \n",
    "        # Simple train-test split for speed\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "        y_pred = best_model.predict(X_test_scaled)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        results[name] = f1\n",
    "        print(f\"  {name}: F1 = {f1:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac400f10",
   "metadata": {
    "papermill": {
     "duration": 0.002147,
     "end_time": "2025-12-19T19:09:22.122141",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.119994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Experiment 3: Final Model Training with Hold-Out Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac71259",
   "metadata": {
    "papermill": {
     "duration": 0.002094,
     "end_time": "2025-12-19T19:09:22.126465",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.124371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Goal: Report final performance on a never-seen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0460cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:09:22.132101Z",
     "iopub.status.busy": "2025-12-19T19:09:22.131487Z",
     "iopub.status.idle": "2025-12-19T19:09:22.138229Z",
     "shell.execute_reply": "2025-12-19T19:09:22.137585Z"
    },
    "papermill": {
     "duration": 0.01096,
     "end_time": "2025-12-19T19:09:22.139598",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.128638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X, y, best_model_name, best_params):\n",
    "    \"\"\"Train final model on full train+val, evaluate on held-out test.\"\"\"\n",
    "    # Split: 70% train, 15% val, 15% test\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, stratify=y_temp, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    if best_model_name == 'SVM':\n",
    "        model = SVC(**best_params, random_state=42)\n",
    "    else:\n",
    "        model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nüéØ FINAL MODEL PERFORMANCE (Hold-Out Test Set)\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"F1-Score: {test_f1:.4f}\")\n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Grade 1', 'Grade 2', 'Grade 3', 'Grade 4']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Grade 1', 'Grade 2', 'Grade 3', 'Grade 4'],\n",
    "                yticklabels=['Grade 1', 'Grade 2', 'Grade 3', 'Grade 4'])\n",
    "    plt.title('Handcrafted Features - Confusion Matrix')\n",
    "    plt.savefig('/kaggle/working/handcrafted_cm.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89119242",
   "metadata": {
    "papermill": {
     "duration": 0.002258,
     "end_time": "2025-12-19T19:09:22.144069",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.141811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3: Full Experimental Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e33d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:09:22.149787Z",
     "iopub.status.busy": "2025-12-19T19:09:22.149284Z",
     "iopub.status.idle": "2025-12-19T19:17:48.863337Z",
     "shell.execute_reply": "2025-12-19T19:17:48.862507Z"
    },
    "papermill": {
     "duration": 506.718751,
     "end_time": "2025-12-19T19:17:48.865041",
     "exception": false,
     "start_time": "2025-12-19T19:09:22.146290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Handcrafted Features Pipeline\n",
      "==================================================\n",
      "üîÑ Extracting handcrafted features from /kaggle/input/processed-images-224x224/...\n",
      "üìÅ Loaded 4603 images from /kaggle/input/processed-images-224x224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4603/4603 [02:46<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 4603 samples with 93 features\n",
      "\n",
      "üîç Evaluating SVM with Nested CV...\n",
      "  ‚Üí Mean F1: 0.9578 ¬± 0.0047\n",
      "\n",
      "üîç Evaluating RandomForest with Nested CV...\n",
      "  ‚Üí Mean F1: 0.9211 ¬± 0.0060\n",
      "\n",
      "üèÜ Best Model: SVM\n",
      "\n",
      "üî¨ Feature Ablation Study:\n",
      "  Color Histograms: F1 = 0.8807\n",
      "  Statistical Features: F1 = 0.9159\n",
      "  Texture (GLCM): F1 = 0.8213\n",
      "  Color + Stats: F1 = 0.9188\n",
      "  Color + Texture: F1 = 0.9123\n",
      "  Stats + Texture: F1 = 0.9324\n",
      "  All Features: F1 = 0.9345\n",
      "\n",
      "‚úÖ Final Test F1: 0.9623\n"
     ]
    }
   ],
   "source": [
    "def run_handcrafted_features_experiment():\n",
    "    print(\"üöÄ Starting Handcrafted Features Pipeline\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Extract features\n",
    "    X, y, paths = extract_dataset_features()\n",
    "    \n",
    "    # Save feature lengths for ablation\n",
    "    sample_feat = extract_features(paths[0])\n",
    "    hist_len = 64  # 32 bins * 2 channels\n",
    "    stat_len = 9   # 3 stats * 3 channels\n",
    "    glcm_len = 20  # 5 props * 4 angles\n",
    "    \n",
    "    # 2. Avoid data leakage: standardize AFTER split\n",
    "    # But for now, just record lengths\n",
    "    feature_lengths = {'hist': hist_len, 'stat': stat_len, 'glcm': glcm_len}\n",
    "    \n",
    "    # 3. Experiment 1: Model selection\n",
    "    model_results = model_selection_nested_cv(X, y)\n",
    "    best_model_name = max(model_results, key=lambda k: model_results[k]['mean_f1'])\n",
    "    print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "    \n",
    "    # 4. Experiment 2: Feature ablation\n",
    "    print(\"\\nüî¨ Feature Ablation Study:\")\n",
    "    ablation_results = feature_ablation_study(X, y, feature_lengths)\n",
    "    \n",
    "    # 5. Train final model (using best config from nested CV)\n",
    "    # For simplicity, we'll re-tune on full data (in practice, use best_params from nested CV)\n",
    "    if best_model_name == 'SVM':\n",
    "        final_model = SVC(C=10, gamma='scale', random_state=42)\n",
    "    else:\n",
    "        final_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "    \n",
    "    # Train and evaluate on hold-out test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    final_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = final_model.predict(X_test_scaled)\n",
    "    final_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Final Test F1: {final_f1:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': [best_model_name],\n",
    "        'Test F1': [final_f1],\n",
    "        'Feature_Ablation': [ablation_results]\n",
    "    })\n",
    "    results_df.to_csv('/kaggle/working/handcrafted_results.csv', index=False)\n",
    "    \n",
    "    return final_model, scaler\n",
    "\n",
    "# Run it\n",
    "if __name__ == \"__main__\":\n",
    "    model, scaler = run_handcrafted_features_experiment()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8329859,
     "sourceId": 13147408,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 519.847037,
   "end_time": "2025-12-19T19:17:51.540235",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-19T19:09:11.693198",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

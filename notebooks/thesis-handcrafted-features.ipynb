{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13147408,"sourceType":"datasetVersion","datasetId":8329859}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Step 1: Full Handcrafted Features Pipeline (Lab* + GLCM + Stats)","metadata":{}},{"cell_type":"code","source":"import os\n\ndata_dir = \"/kaggle/input/processed-images-224x224\"\nfor grade in [\"Grade 1\", \"Grade 2\", \"Grade 3\", \"Grade 4\"]:\n    folder = os.path.join(data_dir, grade)\n    count = len([f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]) if os.path.exists(folder) else 0\n    print(f\"{folder}: {count} images\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\nfrom skimage.feature import graycomatrix, graycoprops \nfrom skimage import img_as_ubyte\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ------------------ FEATURE EXTRACTION ------------------\n\ndef load_and_convert_to_lab(image_path):\n    \"\"\"Load image and convert directly to L*a*b* (no background removal).\"\"\"\n    img = cv2.imread(image_path)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n    return img_lab\n\ndef extract_color_histograms(lab_img, bins=32):\n    \"\"\"Extract normalized histograms for a* and b* channels.\"\"\"\n    a_channel = lab_img[:, :, 1]\n    b_channel = lab_img[:, :, 2]\n    hist_a, _ = np.histogram(a_channel.ravel(), bins=bins, range=(0, 256), density=True)\n    hist_b, _ = np.histogram(b_channel.ravel(), bins=bins, density=True)\n    return np.concatenate([hist_a, hist_b])\n\ndef extract_statistical_features(lab_img):\n    \"\"\"Mean, std, skew for L*, a*, b*.\"\"\"\n    features = []\n    for i in range(3):  # L=0, a=1, b=2\n        channel = lab_img[:, :, i].astype(np.float64)\n        mean = np.mean(channel)\n        std = np.std(channel)\n        skew = (np.mean((channel - mean) ** 3)) / (std ** 3 + 1e-6)\n        features.extend([mean, std, skew])\n    return np.array(features)\n\ndef extract_glcm_features(lab_img, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n    \"\"\"GLCM on L* channel (luminance = texture).\"\"\"\n    l_channel = lab_img[:, :, 0]\n    l_ubyte = img_as_ubyte(l_channel / 255.0)  # Normalize to [0,1] then to 8-bit\n    \n    features = []\n    for dist in distances:\n        for angle in angles:\n            glcm = graycomatrix(l_ubyte, distances=[dist], angles=[angle], levels=256, symmetric=True, normed=True)\n            for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']:\n                features.append(graycoprops(glcm, prop)[0, 0])\n    return np.array(features)\n\ndef extract_features(image_path):\n    \"\"\"Main feature extractor ‚Äî no background removal.\"\"\"\n    try:\n        lab_img = load_and_convert_to_lab(image_path)\n        hist_feat = extract_color_histograms(lab_img)\n        stat_feat = extract_statistical_features(lab_img)\n        glcm_feat = extract_glcm_features(lab_img)\n        return np.concatenate([hist_feat, stat_feat, glcm_feat])\n    except Exception as e:\n        print(f\"Error processing {image_path}: {e}\")\n        return None\n\n# ------------------ DATA LOADING ------------------\n\ndef load_dataset(data_dir=\"/kaggle/input/processed-images-224x224\"):\n    \"\"\"\n    Load images from your actual folder structure:\n    /kaggle/input/processed-images-224x224/Grade 1/\n    /kaggle/input/processed-images-224x224/Grade 2/\n    etc.\n    \"\"\"\n    grade_folders = {\n        'Grade 1': 0,\n        'Grade 2': 1,\n        'Grade 3': 2,\n        'Grade 4': 3\n    }\n    \n    image_paths = []\n    labels = []\n    \n    for grade_name, label in grade_folders.items():\n        folder_path = os.path.join(data_dir, grade_name)\n        if not os.path.exists(folder_path):\n            print(f\"‚ö†Ô∏è Warning: Folder not found: {folder_path}\")\n            continue\n        \n        for f in os.listdir(folder_path):\n            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n                image_paths.append(os.path.join(folder_path, f))\n                labels.append(label)\n    \n    print(f\"üìÅ Loaded {len(image_paths)} images from {data_dir}\")\n    return image_paths, labels\n\n# ------------------ FEATURE EXTRACTION RUNNER ------------------\n\ndef extract_dataset_features():\n    \"\"\"No resolution argument ‚Äî uses fixed input path.\"\"\"\n    print(\"üîÑ Extracting handcrafted features from /kaggle/input/processed-images-224x224/...\")\n    image_paths, labels = load_dataset()  # Uses default path\n    \n    if len(image_paths) == 0:\n        raise ValueError(\"‚ùå No images found! Check your input folder structure.\")\n    \n    features = []\n    valid_paths, valid_labels = [], []\n    \n    for path, label in tqdm(zip(image_paths, labels), total=len(image_paths)):\n        feat = extract_features(path)\n        if feat is not None:\n            features.append(feat)\n            valid_paths.append(path)\n            valid_labels.append(label)\n    \n    if len(features) == 0:\n        raise RuntimeError(\"‚ùå All feature extractions failed.\")\n    \n    X = np.array(features)\n    y = np.array(valid_labels)\n    print(f\"‚úÖ Extracted {X.shape[0]} samples with {X.shape[1]} features\")\n    return X, y, valid_paths","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Anti-Overfitting Experimental Design","metadata":{}},{"cell_type":"markdown","source":"### To find the best model without overfitting, use this 3-stage validation strategy:","metadata":{}},{"cell_type":"markdown","source":"### Experiment 1: Model Selection with Nested Cross-Validation","metadata":{}},{"cell_type":"markdown","source":"Goal: Unbiased comparison of SVM vs Random Forest.","metadata":{}},{"cell_type":"code","source":"def model_selection_nested_cv(X, y, n_splits=5):\n    \"\"\"Nested CV: outer loop for evaluation, inner loop for hyperparameter tuning.\"\"\"\n    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    \n    models = {\n        'SVM': {\n            'model': SVC(random_state=42),\n            'params': {\n                'C': [0.1, 1, 10, 100],\n                'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n            }\n        },\n        'RandomForest': {\n            'model': RandomForestClassifier(random_state=42),\n            'params': {\n                'n_estimators': [100, 200],\n                'max_depth': [None, 10, 20],\n                'min_samples_split': [2, 5, 10]\n            }\n        }\n    }\n    \n    results = {}\n    \n    for name, cfg in models.items():\n        print(f\"\\nüîç Evaluating {name} with Nested CV...\")\n        outer_scores = []\n        \n        for train_idx, test_idx in outer_cv.split(X, y):\n            X_train, X_test = X[train_idx], X[test_idx]\n            y_train, y_test = y[train_idx], y[test_idx]\n            \n            # Standardize features\n            scaler = StandardScaler()\n            X_train_scaled = scaler.fit_transform(X_train)\n            X_test_scaled = scaler.transform(X_test)\n            \n            # Inner CV for hyperparameter tuning\n            inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n            grid = GridSearchCV(cfg['model'], cfg['params'], cv=inner_cv, scoring='f1_weighted', n_jobs=-1)\n            grid.fit(X_train_scaled, y_train)\n            \n            # Evaluate on outer test set\n            y_pred = grid.predict(X_test_scaled)\n            score = f1_score(y_test, y_pred, average='weighted')\n            outer_scores.append(score)\n        \n        results[name] = {\n            'mean_f1': np.mean(outer_scores),\n            'std_f1': np.std(outer_scores),\n            'scores': outer_scores\n        }\n        print(f\"  ‚Üí Mean F1: {np.mean(outer_scores):.4f} ¬± {np.std(outer_scores):.4f}\")\n    \n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Experiment 2: Feature Ablation Study","metadata":{}},{"cell_type":"markdown","source":"Goal: Understand which feature groups (color, stats, texture) matter most.","metadata":{}},{"cell_type":"code","source":"def feature_ablation_study(X, y, feature_lengths):\n    \"\"\"Test performance with subsets of features.\"\"\"\n    hist_len = feature_lengths['hist']\n    stat_len = feature_lengths['stat']\n    glcm_len = feature_lengths['glcm']\n    \n    feature_sets = {\n        'Color Histograms': (0, hist_len),\n        'Statistical Features': (hist_len, hist_len + stat_len),\n        'Texture (GLCM)': (hist_len + stat_len, hist_len + stat_len + glcm_len),\n        'Color + Stats': (0, hist_len + stat_len),\n        'Color + Texture': (0, hist_len) + (hist_len + stat_len, hist_len + stat_len + glcm_len),  # tuple hack\n        'Stats + Texture': (hist_len, hist_len + stat_len + glcm_len),\n        'All Features': (0, X.shape[1])\n    }\n    \n    best_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n    results = {}\n    \n    for name, idx in feature_sets.items():\n        if isinstance(idx, tuple) and len(idx) == 4:  # Handle combined non-contiguous\n            X_subset = np.concatenate([X[:, idx[0]:idx[1]], X[:, idx[2]:idx[3]]], axis=1)\n        else:\n            X_subset = X[:, idx[0]:idx[1]]\n        \n        # Simple train-test split for speed\n        X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, stratify=y, random_state=42)\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n        \n        best_model.fit(X_train_scaled, y_train)\n        y_pred = best_model.predict(X_test_scaled)\n        f1 = f1_score(y_test, y_pred, average='weighted')\n        results[name] = f1\n        print(f\"  {name}: F1 = {f1:.4f}\")\n    \n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Experiment 3: Final Model Training with Hold-Out Test Set","metadata":{}},{"cell_type":"markdown","source":"Goal: Report final performance on a never-seen test set.","metadata":{}},{"cell_type":"code","source":"def train_final_model(X, y, best_model_name, best_params):\n    \"\"\"Train final model on full train+val, evaluate on held-out test.\"\"\"\n    # Split: 70% train, 15% val, 15% test\n    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, stratify=y_temp, random_state=42)\n    \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n    X_test_scaled = scaler.transform(X_test)\n    \n    if best_model_name == 'SVM':\n        model = SVC(**best_params, random_state=42)\n    else:\n        model = RandomForestClassifier(**best_params, random_state=42)\n    \n    model.fit(X_train_scaled, y_train)\n    \n    # Evaluate on test set\n    y_pred = model.predict(X_test_scaled)\n    test_f1 = f1_score(y_test, y_pred, average='weighted')\n    test_acc = accuracy_score(y_test, y_pred)\n    \n    print(\"\\nüéØ FINAL MODEL PERFORMANCE (Hold-Out Test Set)\")\n    print(f\"Accuracy: {test_acc:.4f}\")\n    print(f\"F1-Score: {test_f1:.4f}\")\n    print(\"\\nüìã Classification Report:\")\n    print(classification_report(y_test, y_pred, target_names=['Grade 1', 'Grade 2', 'Grade 3', 'Grade 4']))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=['Grade 1', 'Grade 2', 'Grade 3', 'Grade 4'],\n                yticklabels=['Grade 1', 'Grade 2', 'Grade 3', 'Grade 4'])\n    plt.title('Handcrafted Features - Confusion Matrix')\n    plt.savefig('/kaggle/working/handcrafted_cm.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    return model, scaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Full Experimental Run","metadata":{}},{"cell_type":"code","source":"def run_handcrafted_features_experiment():\n    print(\"üöÄ Starting Handcrafted Features Pipeline\")\n    print(\"=\" * 50)\n    \n    # 1. Extract features\n    X, y, paths = extract_dataset_features()\n    \n    # Save feature lengths for ablation\n    sample_feat = extract_features(paths[0])\n    hist_len = 64  # 32 bins * 2 channels\n    stat_len = 9   # 3 stats * 3 channels\n    glcm_len = 20  # 5 props * 4 angles\n    \n    # 2. Avoid data leakage: standardize AFTER split\n    # But for now, just record lengths\n    feature_lengths = {'hist': hist_len, 'stat': stat_len, 'glcm': glcm_len}\n    \n    # 3. Experiment 1: Model selection\n    model_results = model_selection_nested_cv(X, y)\n    best_model_name = max(model_results, key=lambda k: model_results[k]['mean_f1'])\n    print(f\"\\nüèÜ Best Model: {best_model_name}\")\n    \n    # 4. Experiment 2: Feature ablation\n    print(\"\\nüî¨ Feature Ablation Study:\")\n    ablation_results = feature_ablation_study(X, y, feature_lengths)\n    \n    # 5. Train final model (using best config from nested CV)\n    # For simplicity, we'll re-tune on full data (in practice, use best_params from nested CV)\n    if best_model_name == 'SVM':\n        final_model = SVC(C=10, gamma='scale', random_state=42)\n    else:\n        final_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n    \n    # Train and evaluate on hold-out test\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    final_model.fit(X_train_scaled, y_train)\n    y_pred = final_model.predict(X_test_scaled)\n    final_f1 = f1_score(y_test, y_pred, average='weighted')\n    \n    print(f\"\\n‚úÖ Final Test F1: {final_f1:.4f}\")\n    \n    # Save results\n    results_df = pd.DataFrame({\n        'Model': [best_model_name],\n        'Test F1': [final_f1],\n        'Feature_Ablation': [ablation_results]\n    })\n    results_df.to_csv('/kaggle/working/handcrafted_results.csv', index=False)\n    \n    return final_model, scaler\n\n# Run it\nif __name__ == \"__main__\":\n    model, scaler = run_handcrafted_features_experiment()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}